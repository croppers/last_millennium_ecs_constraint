{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cfr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m>>> job.configs[\"prior_path\"] = {'tas': 'data/ppe/tas_sfc_Amon_iCESM_past1000historical_085001-200512.nc', 'pr': 'data/ppe/'}\n",
      "\u001b[36m\u001b[1m>>> job.configs[\"prior_anom_period\"] = (1850, 1870)\n",
      "\u001b[36m\u001b[1m>>> job.configs[\"prior_lon_name\"] = lon\n",
      "\u001b[36m\u001b[1m>>> job.configs[\"prior_time_name\"] = time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/croppers/miniconda3/envs/LMRt/lib/python3.8/site-packages/xarray/backends/plugins.py:139: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/work/croppers/miniconda3/envs/LMRt/lib/python3.8/site-packages/xarray/backends/plugins.py:139: RuntimeWarning: 'scipy' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/work/croppers/miniconda3/envs/LMRt/lib/python3.8/site-packages/xarray/backends/plugins.py:148: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/work/croppers/miniconda3/envs/LMRt/lib/python3.8/site-packages/xarray/backends/plugins.py:148: RuntimeWarning: 'h5netcdf' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/work/croppers/miniconda3/envs/LMRt/lib/python3.8/site-packages/xarray/backends/plugins.py:148: RuntimeWarning: 'scipy' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# load the pseudoPAGES2k database from a netCDF file\u001b[39;00m\n\u001b[1;32m      5\u001b[0m job\u001b[38;5;241m.\u001b[39mproxydb \u001b[38;5;241m=\u001b[39m cfr\u001b[38;5;241m.\u001b[39mProxyDatabase()\u001b[38;5;241m.\u001b[39mload_nc(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/ppe/ppwn_SNR10_rta.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_clim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprior\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtas\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/ppe/tas_sfc_Amon_iCESM_past1000historical_085001-200512.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/ppe/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43manom_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1850\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1870\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# calculate anomalies against the reference interval 1850-1870 CE\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m job\u001b[38;5;241m.\u001b[39mload_clim(\n\u001b[1;32m     18\u001b[0m     tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m     path_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# PSM to be used\u001b[39;00m\n",
      "File \u001b[0;32m/work/croppers/miniconda3/envs/LMRt/lib/python3.8/site-packages/cfr/reconjob.py:274\u001b[0m, in \u001b[0;36mReconJob.load_clim\u001b[0;34m(self, tag, path_dict, rename_dict, anom_period, time_name, lon_name, verbose)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[tag][vn] \u001b[38;5;241m=\u001b[39m \u001b[43mClimateField\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_nc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvn_in_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_anom(ref_period\u001b[38;5;241m=\u001b[39manom_period)\u001b[38;5;241m.\u001b[39mwrap_lon(lon_name\u001b[38;5;241m=\u001b[39mlon_name, time_name\u001b[38;5;241m=\u001b[39mtime_name)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m time_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[tag][vn] \u001b[38;5;241m=\u001b[39m ClimateField()\u001b[38;5;241m.\u001b[39mload_nc(path, vn\u001b[38;5;241m=\u001b[39mvn_in_file, time_name\u001b[38;5;241m=\u001b[39mtime_name)\u001b[38;5;241m.\u001b[39mcenter(ref_period\u001b[38;5;241m=\u001b[39manom_period, time_name\u001b[38;5;241m=\u001b[39mtime_name)\u001b[38;5;241m.\u001b[39mwrap_lon(lon_name\u001b[38;5;241m=\u001b[39mlon_name, time_name\u001b[38;5;241m=\u001b[39mtime_name)\n",
      "File \u001b[0;32m/work/croppers/miniconda3/envs/LMRt/lib/python3.8/site-packages/cfr/climate.py:167\u001b[0m, in \u001b[0;36mClimateField.load_nc\u001b[0;34m(self, path, vn, time_name, lat_name, lon_name, load, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     da \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataarray(path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     da \u001b[38;5;241m=\u001b[39m ds[vn]\n\u001b[1;32m    170\u001b[0m new \u001b[38;5;241m=\u001b[39m ClimateField(da\u001b[38;5;241m=\u001b[39mda, time_name\u001b[38;5;241m=\u001b[39mtime_name, lat_name\u001b[38;5;241m=\u001b[39mlat_name, lon_name\u001b[38;5;241m=\u001b[39mlon_name)\n",
      "File \u001b[0;32m/work/croppers/miniconda3/envs/LMRt/lib/python3.8/site-packages/xarray/backends/api.py:525\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(backend_kwargs)\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguess_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m backend \u001b[38;5;241m=\u001b[39m plugins\u001b[38;5;241m.\u001b[39mget_backend(engine)\n\u001b[1;32m    529\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    530\u001b[0m     decode_cf,\n\u001b[1;32m    531\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    538\u001b[0m )\n",
      "File \u001b[0;32m/work/croppers/miniconda3/envs/LMRt/lib/python3.8/site-packages/xarray/backends/plugins.py:177\u001b[0m, in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound the following matches with the input file in xarray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms IO \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompatible_engines\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. But their dependencies may not be installed, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html"
     ]
    }
   ],
   "source": [
    "# create a reconstruction job object using the `cfr.ReconJob` class\n",
    "job = cfr.ReconJob()\n",
    "\n",
    "# load the pseudoPAGES2k database from a netCDF file\n",
    "job.proxydb = cfr.ProxyDatabase().load_nc('data/ppe/ppwn_SNR10_rta.nc')\n",
    "\n",
    "job.load_clim(\n",
    "    tag='prior',\n",
    "    path_dict={\n",
    "        'tas': 'data/ppe/tas_sfc_Amon_iCESM_past1000historical_085001-200512.nc',\n",
    "        'pr': 'data/ppe/',\n",
    "    },\n",
    "    anom_period=(1850, 1870),  # calculate anomalies against the reference interval 1850-1870 CE\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "job.load_clim(\n",
    "    tag='obs',\n",
    "    path_dict={\n",
    "        'tas': 'data/ppe/tas_sfc_Amon_iCESM_past1000historical_085001-200512.nc',\n",
    "        'pr': 'data/ppe/',\n",
    "    },\n",
    "    anom_period=(1850, 1870),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# PSM to be used\n",
    "ptype_psm_dict = {\n",
    "    'tree.TRW': 'Bilinear',\n",
    "    'tree.MXD': 'Linear',\n",
    "    'coral.d18O': 'Linear',\n",
    "    'coral.SrCa': 'Linear',\n",
    "    'ice.d18O': 'Linear',\n",
    "    'lake.varve_thickness': 'Linear',\n",
    "}\n",
    "\n",
    "# Seasonality for each proxy type\n",
    "ptype_season_dict = {\n",
    "    'tree.TRW': [  # expert curated pool of possible growing seasons\n",
    "        [1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "        [6,7,8],\n",
    "        [3,4,5,6,7,8],\n",
    "        [6,7,8,9,10,11],\n",
    "        [-12,1,2],\n",
    "        [-9,-10,-11,-12,1,2],\n",
    "        [-12,1,2,3,4,5],\n",
    "    ],\n",
    "    'tree.MXD': [  # expert curated pool of possible growing seasons\n",
    "        [1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "        [6,7,8],\n",
    "        [3,4,5,6,7,8],\n",
    "        [6,7,8,9,10,11],\n",
    "        [-12,1,2],\n",
    "        [-9,-10,-11,-12,1,2],\n",
    "        [-12,1,2,3,4,5],\n",
    "    ],\n",
    "    'coral.d18O': list(range(1, 13)),            # annual\n",
    "    'coral.SrCa': list(range(1, 13)),            # annual\n",
    "    'ice.d18O': list(range(1, 13)),              # annual\n",
    "    'lake.varve_thickness': list(range(1, 13)),  # annual\n",
    "}\n",
    "\n",
    "job.calib_psms(\n",
    "    ptype_psm_dict=ptype_psm_dict,\n",
    "    ptype_season_dict=ptype_season_dict,\n",
    "    verbose=True,)\n",
    "\n",
    "job.forward_psms(verbose=True)\n",
    "\n",
    "job.annualize_clim(tag='prior', verbose=True, months=list(range(1, 13)))\n",
    "\n",
    "job.regrid_clim(tag='prior', nlat=42, nlon=63, verbose=True)\n",
    "\n",
    "job.save('data/ppe/job-lmr-ppe-pages2k', verbose=True)\n",
    "\n",
    "job = cfr.ReconJob()\n",
    "job.load('data/ppe/job-lmr-ppe-pages2k/', verbose=True)\n",
    "\n",
    "job.prior['pr'].da.values *= 1e5  # to regularize the pr values\n",
    "\n",
    "job.run_da_mc(\n",
    "    save_dirpath='data/ppe/results/lmr-ppe-pages2k',\n",
    "    recon_seeds=list(range(1, 21)),\n",
    "    recon_vars=['tas', 'pr'],  # to reconstruct the tas and pr fields\n",
    "    recon_period=[800, 2000],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "xr.open_dataset('data/ppe/tas_sfc_Amon_iCESM_past1000historical_085001-200512.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LMRt",
   "language": "python",
   "name": "lmrt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b69765b4611529555a72e5a38db3137e103f908b34918dc42c74c3aeee6aa325"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
