{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adjustText import adjust_text\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.stats import linregress\n",
    "import matplotlib as mpl\n",
    "from statsmodels.api import tsa\n",
    "import statsmodels.api as sm\n",
    "import xarray as xr\n",
    "\n",
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "# mpl.rcParams['font.sans-serif'] = ['Helvetica']\n",
    "mpl.rcParams['font.size'] = 12\n",
    "\n",
    "def get_forcing(saod):\n",
    "    '''\n",
    "    Takes in a timeseries of SAOD (numpy array) and outputs a forcing profile (in W/m^2)\n",
    "    '''\n",
    "    return np.multiply(-20.7, np.subtract(1, np.exp(np.multiply(-1, saod))))\n",
    "\n",
    "def remove_volcano(timeseries, temp_anomaly):\n",
    "    X = temp_anomaly # independent variable\n",
    "    y = timeseries   # dependent variable\n",
    "\n",
    "    # to get intercept -- this is optional\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # fit the regression model\n",
    "    reg = sm.OLS(y, X).fit()\n",
    "    \n",
    "    return reg.resid.values\n",
    "\n",
    "# take a spatial average\n",
    "def weighted_mean(da):\n",
    "    \n",
    "    # make 2d array of weights in case that lat is 1d\n",
    "    if len(da.lat.shape)==2:\n",
    "        weights=np.cos(np.deg2rad(da.lat))\n",
    "    elif len(da.lat.shape)==1:\n",
    "        weights = xr.ones_like(da)* (np.cos(np.deg2rad((da.lat))).values)\n",
    "    \n",
    "    # turn weights into nan where da is nan\n",
    "    weights = weights*da/da\n",
    "    \n",
    "    if 'lat' in da.dims:\n",
    "        wm = (da*weights).sum(dim=['lat'], skipna=True) / weights.sum(dim=['lat'], skipna=True)\n",
    "    elif 'i' in da.dims:\n",
    "        wm = (da*weights).sum(dim=['i','j'], skipna=True) / weights.sum(dim=['i','j'], skipna=True)\n",
    "    elif 'nlat' in da.dims:\n",
    "        wm = (da*weights).sum(dim=['nlat','nlon'], skipna=True) / weights.sum(dim=['nlat','nlon'], skipna=True)\n",
    "    elif 'x' in da.dims:\n",
    "        wm = (da*weights).sum(dim=['x','y'], skipna=True) / weights.sum(dim=['x','y'], skipna=True)\n",
    "    return wm\n",
    "\n",
    "def compute_cox(x):\n",
    "    x = x[~np.isnan(x)]\n",
    "    psi_vals=[]\n",
    "    for i in np.arange(0, len(x)-55):\n",
    "        y = signal.detrend(x[i:i+55])\n",
    "        auto_m1 = tsa.acf(y,nlags=1) # autocorrelation function from statsmodels\n",
    "        auto_m1b = auto_m1[1]    # select 1 lag autocorrelation value\n",
    "        sigma_m1= np.std(y)\n",
    "        log_m1= np.log(auto_m1b)\n",
    "        log_m1b = np.abs(log_m1)   # take absolute value\n",
    "        sqrt_m1 = np.sqrt(log_m1b)\n",
    "        psi = sigma_m1/sqrt_m1\n",
    "        psi_vals.append(psi)\n",
    "    return np.nanmean(psi_vals)\n",
    "\n",
    "def compute_nijsse(x, length=10):\n",
    "    # remove NaNs from the timeseries\n",
    "    x = np.array(x)\n",
    "    mask = ~np.isnan(x)\n",
    "    x = x[mask]\n",
    "    # fill it with slopes\n",
    "    slopes = []\n",
    "    i = 0\n",
    "    while i < len(x)-length:\n",
    "        slope, intercept, r, p, se = linregress(np.arange(0,length), x[i:i+length])\n",
    "        slopes.append(length*slope)\n",
    "        i+=length\n",
    "    return np.nanstd(slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolv2k_ts = weighted_mean(xr.open_dataset('data/evolv2k.nc')).sel(time=slice(850,1850))\n",
    "evolv2k_saod = []\n",
    "i=850\n",
    "while i <= 1850:\n",
    "    evolv2k_saod.append(float(evolv2k_ts.sel(time=slice(i, i+1)).mean(dim='time').aod550.values))\n",
    "    i+=1\n",
    "evolv2k_forcing = get_forcing(evolv2k_saod)\n",
    "\n",
    "gao_2008_saod = np.divide(pd.read_csv('data/gao_2008.csv')['gm'].values.astype(float), 1.2*10**3)\n",
    "gao_2008_forcing = get_forcing(gao_2008_saod)\n",
    "\n",
    "crowley_2000_forcing = pd.read_csv('data/crowley_2000.txt', delimiter = '\\t')['Vol.hl.cct'].values\n",
    "\n",
    "crowley_2008_saod = pd.read_csv('data/crowley_2008.txt', delimiter = '\\t')['AOD'].values\n",
    "crowley_2008_forcing = get_forcing(crowley_2008_saod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcc-csm1-1\n",
      "CCSM4\n",
      "CSIRO-Mk3L\n",
      "FGOALS-gl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_119824/803090135.py:65: RuntimeWarning: invalid value encountered in log\n",
      "  log_m1= np.log(auto_m1b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GISS-E2-R\n",
      "HadCM3\n",
      "IPSL-CM5A-LR\n",
      "MIROC-ES2L\n",
      "MPI-ESM-P\n",
      "MRI-CGCM3\n",
      "MRI-ESM2-0\n",
      "CESM1-LME\n",
      "CESM2\n",
      "MPI-ESM1-2-LR\n",
      "EC-Earth3-Veg-LR\n",
      "MIROC-ESM\n",
      "INM-CM4-8\n",
      "ACCESS-ESM1-5\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/ts.csv')\n",
    "model_keys = df.keys()[2:]\n",
    "forcings = ['gao', 'gao', 'crowley_08', 'crowley_00',\n",
    "            'evolv2k', 'crowley_08', 'gao', 'evolv2k',\n",
    "            'crowley_08', 'gao', 'evolv2k', 'gao', \n",
    "            'evolv2k', 'evolv2k', 'evolv2k', 'crowley_08',\n",
    "            'evolv2k', 'evolv2k']\n",
    "ecs_vals = []\n",
    "original_cox = []\n",
    "rv_cox = []\n",
    "original_nijsse = []\n",
    "rv_nijsse = []\n",
    "\n",
    "t = pd.read_csv('data/ecs.csv')\n",
    "\n",
    "df_rv = {}\n",
    "\n",
    "for i in range(len(model_keys)):\n",
    "    print(model_keys[i])\n",
    "    ts = df[model_keys[i]].values\n",
    "    ts_historical = ts[1001:]\n",
    "    ts_past1000 = ts[:1001]\n",
    "    if model_keys[i] == 'HadCM3':\n",
    "        X = crowley_2008_forcing\n",
    "        y = ts_past1000\n",
    "        X = sm.add_constant(X)\n",
    "        reg = sm.OLS(y, X).fit()\n",
    "        ecs_vals.append(t[t['model name']==model_keys[i]]['ecs'].values[0])\n",
    "        original_cox.append(compute_cox(ts))\n",
    "        rv_cox.append(compute_cox(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        original_nijsse.append(compute_nijsse(ts))\n",
    "        rv_nijsse.append(compute_nijsse(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        df_rv[model_keys[i]] = np.append(np.add(reg.resid, reg.params[0]), ts_historical)\n",
    "    elif forcings[i] == 'gao':\n",
    "        X = gao_2008_forcing\n",
    "        y = ts_past1000\n",
    "        X = sm.add_constant(X)\n",
    "        reg = sm.OLS(y, X).fit()\n",
    "        ecs_vals.append(t[t['model name']==model_keys[i]]['ecs'].values[0])\n",
    "        original_cox.append(compute_cox(ts))\n",
    "        rv_cox.append(compute_cox(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        original_nijsse.append(compute_nijsse(ts))\n",
    "        rv_nijsse.append(compute_nijsse(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        df_rv[model_keys[i]] = np.append(np.add(reg.resid, reg.params[0]), ts_historical)\n",
    "    elif forcings[i] == 'crowley_00':\n",
    "        X = crowley_2000_forcing\n",
    "        y = ts[150:150+999]\n",
    "        X = sm.add_constant(X)\n",
    "        reg = sm.OLS(y, X).fit()\n",
    "        ecs_vals.append(t[t['model name']==model_keys[i]]['ecs'].values[0])\n",
    "        original_cox.append(compute_cox(ts))\n",
    "        rv_cox.append(compute_cox(np.add(reg.resid, reg.params[0])))\n",
    "        original_nijsse.append(compute_nijsse(ts))\n",
    "        rv_nijsse.append(compute_nijsse(np.add(reg.resid, reg.params[0])))\n",
    "        df_rv[model_keys[i]] = np.append(ts[:151],np.add(reg.resid, reg.params[0]))\n",
    "    elif forcings[i] == 'crowley_08':\n",
    "        X = crowley_2008_forcing\n",
    "        y = ts_past1000\n",
    "        X = sm.add_constant(X)\n",
    "        reg = sm.OLS(y, X).fit()\n",
    "        ecs_vals.append(t[t['model name']==model_keys[i]]['ecs'].values[0])\n",
    "        original_cox.append(compute_cox(ts))\n",
    "        rv_cox.append(compute_cox(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        original_nijsse.append(compute_nijsse(ts))\n",
    "        rv_nijsse.append(compute_nijsse(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        df_rv[model_keys[i]] = np.append(np.add(reg.resid, reg.params[0]), ts_historical)\n",
    "    elif forcings[i] == 'evolv2k':\n",
    "        X = evolv2k_forcing\n",
    "        y = ts_past1000\n",
    "        X = sm.add_constant(X)\n",
    "        reg = sm.OLS(y, X).fit()\n",
    "        ecs_vals.append(t[t['model name']==model_keys[i]]['ecs'].values[0])\n",
    "        original_cox.append(compute_cox(ts))\n",
    "        rv_cox.append(compute_cox(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        original_nijsse.append(compute_nijsse(ts))\n",
    "        rv_nijsse.append(compute_nijsse(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        df_rv[model_keys[i]] = np.append(np.add(reg.resid, reg.params[0]), ts_historical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'model': model_keys, 'generation': t['generation'].values, 'cox': original_cox, 'rv_cox': rv_cox, 'nijsse': original_nijsse, 'rv_nijsse': rv_nijsse, 'ecs': ecs_vals}\n",
    "pd.DataFrame(df).to_csv('data/ec_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_rv).to_csv('data/ts_rv.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcpy_env",
   "language": "python",
   "name": "gcpy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
