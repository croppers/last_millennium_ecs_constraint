{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate EC Data (generate_ec_data) Notebook\n",
    "\n",
    "This notebook uses the original, global mean annual 'tas' temperature timeseries from each of the 18 models in our paleomodel ensemble.\n",
    "\n",
    "It returns as output two files:\n",
    "* 'ec_data.csv' - a dataset of temperature variability metrics and corresponding ECS values\n",
    "* 'ts_rv.csv' - the original temperature timeseries, but altered such that the volcanic forcing profile is regressed against and what's left is the residuals.\n",
    "\n",
    "Last updated: August 3, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adjustText import adjust_text\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.stats import linregress\n",
    "import matplotlib as mpl\n",
    "from statsmodels.api import tsa\n",
    "import statsmodels.api as sm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "mpl.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define functions used for generating the timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forcing(saod):\n",
    "    '''\n",
    "    This function converts sulfuric aerosol optical depth (SAOD) into radiative forcing.\n",
    "    \n",
    "    input: a timeseries of SAOD (numpy array) [List]\n",
    "    output: a forcing profile (in W/m^2) [List]\n",
    "    \n",
    "    *Formula taken from Marshall et al. (2020): https://doi.org/10.1029/2020GL090241\n",
    "    '''\n",
    "    return np.multiply(-20.7, np.subtract(1, np.exp(np.multiply(-1, saod))))\n",
    "\n",
    "def remove_volcano(timeseries, temp_anomaly):\n",
    "    '''\n",
    "    The purpose of this function is to \"regress out\" biased volcanic influence in the model\n",
    "\n",
    "    input: timeseries, python list timeseries of temperatures from the model [List]\n",
    "           temp_anomaly, a python list of the temperature anomalies induced by volcanic forcing [List]\n",
    "    output: temperature residuals with volcanic forcing 'regressed out' [List]\n",
    "    '''\n",
    "    X = temp_anomaly # independent variable\n",
    "    y = timeseries   # dependent variable\n",
    "\n",
    "    # to get intercept -- this is optional\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # fit the regression model\n",
    "    reg = sm.OLS(y, X).fit()\n",
    "    \n",
    "    return reg.resid.values\n",
    "\n",
    "# take a spatial average\n",
    "def weighted_mean(da):\n",
    "    '''\n",
    "    This function takes a mean.\n",
    "    \n",
    "    input: a data field from GCM output [DataArray]\n",
    "    output: a spatially-weighted mean field [DataArray]\n",
    "    '''\n",
    "    # make 2d array of weights in case that lat is 1d\n",
    "    if len(da.lat.shape)==2:\n",
    "        weights=np.cos(np.deg2rad(da.lat))\n",
    "    elif len(da.lat.shape)==1:\n",
    "        weights = xr.ones_like(da)* (np.cos(np.deg2rad((da.lat))).values)\n",
    "    \n",
    "    # turn weights into nan where da is nan\n",
    "    weights = weights*da/da\n",
    "    \n",
    "    if 'lat' in da.dims:\n",
    "        wm = (da*weights).sum(dim=['lat'], skipna=True) / weights.sum(dim=['lat'], skipna=True)\n",
    "    elif 'i' in da.dims:\n",
    "        wm = (da*weights).sum(dim=['i','j'], skipna=True) / weights.sum(dim=['i','j'], skipna=True)\n",
    "    elif 'nlat' in da.dims:\n",
    "        wm = (da*weights).sum(dim=['nlat','nlon'], skipna=True) / weights.sum(dim=['nlat','nlon'], skipna=True)\n",
    "    elif 'x' in da.dims:\n",
    "        wm = (da*weights).sum(dim=['x','y'], skipna=True) / weights.sum(dim=['x','y'], skipna=True)\n",
    "    return wm\n",
    "\n",
    "def compute_cox(x):\n",
    "    '''\n",
    "    This function computes the Cox metric for a timeseries of temperatures.\n",
    "    \n",
    "    input: inter-annual temperatures [list]\n",
    "    output: the Cox metric [float]\n",
    "    \n",
    "    * taken from Cox et al., 2018: https://doi.org/10.1038/nature25450\n",
    "    '''\n",
    "    \n",
    "    x = x[~np.isnan(x)]\n",
    "    psi_vals=[]\n",
    "    for i in np.arange(0, len(x)-55):\n",
    "        y = signal.detrend(x[i:i+55])\n",
    "        auto_m1 = tsa.acf(y,nlags=1) # autocorrelation function from statsmodels\n",
    "        auto_m1b = auto_m1[1]    # select 1 lag autocorrelation value\n",
    "        sigma_m1= np.std(y)\n",
    "        log_m1= np.log(auto_m1b)\n",
    "        log_m1b = np.abs(log_m1)   # take absolute value\n",
    "        sqrt_m1 = np.sqrt(log_m1b)\n",
    "        psi = sigma_m1/sqrt_m1\n",
    "        psi_vals.append(psi)\n",
    "    return np.nanmean(psi_vals)\n",
    "\n",
    "def compute_nijsse(x, length=10):\n",
    "    '''\n",
    "    This function computes the Nijsse metric for a timeseries of temperatures.\n",
    "    \n",
    "    input: inter-annual temperatures [list]\n",
    "    output: the Nijsse metric [float]\n",
    "    \n",
    "    * taken from Nijsse et al., 2019: https://doi.org/10.1038/s41558-019-0527-4\n",
    "    '''\n",
    "    # remove NaNs from the timeseries\n",
    "    x = np.array(x)\n",
    "    mask = ~np.isnan(x)\n",
    "    x = x[mask]\n",
    "    # fill it with slopes\n",
    "    slopes = []\n",
    "    i = 0\n",
    "    while i < len(x)-length:\n",
    "        slope, intercept, r, p, se = linregress(np.arange(0,length), x[i:i+length])\n",
    "        slopes.append(length*slope)\n",
    "        i+=length\n",
    "    return np.nanstd(slopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regress out some of the volcanic influence in the temperature timeseries from 850-1850. We load each of the four volcanic forcings used by the PMIP3 and PMIP4 past1000/past2k experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolv2k_v3 forcing\n",
    "evolv2k_ts = weighted_mean(xr.open_dataset('data/evolv2k.nc')).sel(time=slice(850,1850))\n",
    "evolv2k_saod = []\n",
    "i=850\n",
    "while i <= 1850:\n",
    "    evolv2k_saod.append(float(evolv2k_ts.sel(time=slice(i, i+1)).mean(dim='time').aod550.values))\n",
    "    i+=1\n",
    "evolv2k_forcing = get_forcing(evolv2k_saod)\n",
    "\n",
    "# Gao et al., (2008) forcing\n",
    "gao_2008_saod = np.divide(pd.read_csv('data/gao_2008.csv')['gm'].values.astype(float), 1.2*10**3)\n",
    "gao_2008_forcing = get_forcing(gao_2008_saod)\n",
    "\n",
    "# Crowley et al., (2000) forcing\n",
    "crowley_2000_forcing = pd.read_csv('data/crowley_2000.txt', delimiter = '\\t')['Vol.hl.cct'].values\n",
    "\n",
    "# Crowley et al., (2008)\n",
    "crowley_2008_saod = pd.read_csv('data/crowley_2008.txt', delimiter = '\\t')['AOD'].values\n",
    "crowley_2008_forcing = get_forcing(crowley_2008_saod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate the timeseries according to the following procedure:\n",
    "1. For each model, load the raw temperature timeseries.\n",
    "2. Next, \"regress out\" some of the volcanic influence.\n",
    "3. Compute the Cox metric for both the original and \"volcanic influence removed\" timeseries\n",
    "4. Compute the Nijsse metric for both the original and \"volcanic influence removed\" timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['FGOALS-gl'][150:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_201421/985049880.py:75: RuntimeWarning: invalid value encountered in log\n",
      "  log_m1= np.log(auto_m1b)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/ts.csv')\n",
    "model_keys = df.keys()[2:]\n",
    "forcings = ['gao', 'gao', 'crowley_08', 'crowley_00',\n",
    "            'evolv2k', 'crowley_08', 'gao', 'evolv2k',\n",
    "            'crowley_08', 'gao', 'evolv2k', 'gao', \n",
    "            'evolv2k', 'evolv2k', 'evolv2k', 'crowley_08',\n",
    "            'evolv2k', 'evolv2k']\n",
    "ecs_vals = []\n",
    "original_cox = []\n",
    "rv_cox = []\n",
    "original_nijsse = []\n",
    "rv_nijsse = []\n",
    "\n",
    "t = pd.read_csv('data/ecs.csv')\n",
    "\n",
    "df_rv = {}\n",
    "\n",
    "for i in range(len(model_keys)):\n",
    "    ts = df[model_keys[i]].values\n",
    "    ts_historical = ts[1001:]\n",
    "    ts_past1000 = ts[:1001]\n",
    "    if model_keys[i] == 'HadCM3':\n",
    "        X = crowley_2008_forcing\n",
    "        y = ts_past1000\n",
    "        X = sm.add_constant(X)\n",
    "        reg = sm.OLS(y, X).fit()\n",
    "        ecs_vals.append(t[t['model name']==model_keys[i]]['ecs'].values[0])\n",
    "        original_cox.append(compute_cox(ts))\n",
    "        rv_cox.append(compute_cox(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        original_nijsse.append(compute_nijsse(ts))\n",
    "        rv_nijsse.append(compute_nijsse(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        df_rv[model_keys[i]] = np.append(np.add(reg.resid, reg.params[0]), ts_historical)\n",
    "    elif forcings[i] == 'gao':\n",
    "        X = gao_2008_forcing\n",
    "        y = ts_past1000\n",
    "        X = sm.add_constant(X)\n",
    "        reg = sm.OLS(y, X).fit()\n",
    "        ecs_vals.append(t[t['model name']==model_keys[i]]['ecs'].values[0])\n",
    "        original_cox.append(compute_cox(ts))\n",
    "        rv_cox.append(compute_cox(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        original_nijsse.append(compute_nijsse(ts))\n",
    "        rv_nijsse.append(compute_nijsse(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        df_rv[model_keys[i]] = np.append(np.add(reg.resid, reg.params[0]), ts_historical)\n",
    "    elif forcings[i] == 'crowley_00':\n",
    "        X = crowley_2000_forcing\n",
    "        y = ts[151:]\n",
    "        X = sm.add_constant(X)\n",
    "        reg = sm.OLS(y, X).fit()\n",
    "        ecs_vals.append(t[t['model name']==model_keys[i]]['ecs'].values[0])\n",
    "        original_cox.append(compute_cox(ts))\n",
    "        rv_cox.append(compute_cox(np.add(reg.resid, reg.params[0])))\n",
    "        original_nijsse.append(compute_nijsse(ts))\n",
    "        rv_nijsse.append(compute_nijsse(np.add(reg.resid, reg.params[0])))\n",
    "        df_rv[model_keys[i]] = np.append(ts[:151],np.add(reg.resid, reg.params[0]))\n",
    "    elif forcings[i] == 'crowley_08':\n",
    "        X = crowley_2008_forcing\n",
    "        y = ts_past1000\n",
    "        X = sm.add_constant(X)\n",
    "        reg = sm.OLS(y, X).fit()\n",
    "        ecs_vals.append(t[t['model name']==model_keys[i]]['ecs'].values[0])\n",
    "        original_cox.append(compute_cox(ts))\n",
    "        rv_cox.append(compute_cox(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        original_nijsse.append(compute_nijsse(ts))\n",
    "        rv_nijsse.append(compute_nijsse(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        df_rv[model_keys[i]] = np.append(np.add(reg.resid, reg.params[0]), ts_historical)\n",
    "    elif forcings[i] == 'evolv2k':\n",
    "        X = evolv2k_forcing\n",
    "        y = ts_past1000\n",
    "        X = sm.add_constant(X)\n",
    "        reg = sm.OLS(y, X).fit()\n",
    "        ecs_vals.append(t[t['model name']==model_keys[i]]['ecs'].values[0])\n",
    "        original_cox.append(compute_cox(ts))\n",
    "        rv_cox.append(compute_cox(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        original_nijsse.append(compute_nijsse(ts))\n",
    "        rv_nijsse.append(compute_nijsse(np.append(np.add(reg.resid, reg.params[0]), ts_historical)))\n",
    "        df_rv[model_keys[i]] = np.append(np.add(reg.resid, reg.params[0]), ts_historical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the emergent constraint relevant data in a file called 'ec_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'model': model_keys, 'generation': t['generation'].values, 'cox': original_cox, 'rv_cox': rv_cox, 'nijsse': original_nijsse, 'rv_nijsse': rv_nijsse, 'ecs': ecs_vals}\n",
    "pd.DataFrame(df).to_csv('data/ec_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, save the timeseries data for each model with the volcanic influence \"regressed out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_rv).to_csv('data/ts_rv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcpy_env",
   "language": "python",
   "name": "gcpy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
